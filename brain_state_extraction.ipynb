{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e11ce94",
   "metadata": {},
   "source": [
    "## Notebook to create brain state files from EF1_ALPHA excel sleep scoring spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe0a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe841820",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/PREPROCESSING/EF1_ALPHA')\n",
    "epoch_number = \"A, E, I, M, Q, U, Y, AC, AG, AK, AO, AS, BA, BE, BI, BM, BQ, BU, BY, CC, CG, CK, CO, CS, CW\"\n",
    "cols = \"B, F, J, N, R, V, Z, AD, AH, AL, AP, AT, BB, BF, BJ, BN, BR, BV, BZ,CD, CH, CL, CP, CT, CX\"\n",
    "cols_discard = \"C, G, K, O, S, W, AA, AE, AI, AM, AQ, AU, BC, BG, BK, BO, BS, BW, CA, CE, CI, CM, CQ, CU, CY\"\n",
    "skiprows = 5\n",
    "raw_excel = pd.read_excel('grant_EEG_classification.xlsx', usecols = cols, header= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf7a4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of animal ids\n",
    "column_names = list(raw_excel)\n",
    "animal_ids = [anim_id[0:10] for anim_id in column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76ec4f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['210422_D', '210423_D', '210705_C', '210706_C', '191125_A', '191126_A', '210705_B', '210706_B', '210705_A', '210706_A', '191216_A_1', '191217_A_1', '191104_B', '191107_A', '191108_A', '210422_B_1', '210423_B_1', '191216_C', '191217_C', '191216_B', '191217_B', '210429_C', '210430_C', '210705_D', '210706_D']\n"
     ]
    }
   ],
   "source": [
    "#strip whitespace\n",
    "animal_ids = [id.replace(\" \", \"\") for id in animal_ids]\n",
    "print(animal_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "016076e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_epochs = pd.read_excel('grant_EEG_classification.xlsx', usecols = epoch_number, header = 1, skiprows = 6)\n",
    "raw_epochs_letter = pd.read_excel('grant_EEG_classification.xlsx', usecols = cols, header = 1, skiprows = 6)\n",
    "raw_discard = pd.read_excel('grant_EEG_classification.xlsx', usecols = cols_discard, header = 1, skiprows = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b8b4dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_files = []\n",
    "for epoch in raw_epochs:\n",
    "    start_epochs = raw_epochs[raw_epochs[epoch] == 0].index.tolist()\n",
    "    two_files.append(start_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f79b9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210422_D\n",
      "210423_D\n",
      "210705_C\n",
      "210706_C\n",
      "191125_A\n",
      "191126_A\n",
      "210705_B\n",
      "210706_B\n",
      "210705_A\n",
      "210706_A\n",
      "191216_A_1\n",
      "191217_A_1\n",
      "191104_B\n",
      "191107_A\n",
      "191108_A\n",
      "210422_B_1\n",
      "210423_B_1\n",
      "191216_C\n",
      "191217_C\n",
      "191216_B\n",
      "191217_B\n",
      "210429_C\n",
      "210430_C\n",
      "210705_D\n",
      "210706_D\n"
     ]
    }
   ],
   "source": [
    "for file, epoch, animal_id, epoch_letter_col, discard_col in zip(two_files, raw_epochs, animal_ids, raw_epochs_letter, raw_discard):\n",
    "    print(animal_id)\n",
    "    if len(file) == 2:\n",
    "        start_2 = file[1:2]\n",
    "        start_2 = start_2[0]\n",
    "        end_epoch = start_2 - 1\n",
    "        epochs_letter = raw_epochs_letter[epoch_letter_col]\n",
    "        drop_na = epochs_letter.dropna()\n",
    "        length_col = len(drop_na) \n",
    "        epoch_column_raw = raw_epochs[epoch]\n",
    "        part_1 = epoch_column_raw[0: end_epoch].astype(int)\n",
    "        part_2 = epoch_column_raw[start_2: length_col].astype(int)\n",
    "        epochs_letter_part_1 = epochs_letter[0:end_epoch]\n",
    "        epochs_letter_part_2 = epochs_letter[start_2: length_col]\n",
    "        discard_data = raw_discard[discard_col]\n",
    "        discard_part_1 = discard_data[0: end_epoch]\n",
    "        discard_part_2 = discard_data[start_2: length_col]\n",
    "        part_1_dict = {'epoch_numbers': part_1, 'brain_state': epochs_letter_part_1,\n",
    "                       'epoch_discard_numbers': discard_part_1}\n",
    "        part_2_dict = {'epoch_numbers': part_2, 'brain_state': epochs_letter_part_2,\n",
    "                      'epoch_discard_numbers': discard_part_2}\n",
    "        df_1 = pd.DataFrame(data = part_1_dict)\n",
    "        df_2 = pd.DataFrame(data = part_2_dict)\n",
    "        os.chdir('/home/melissa/PREPROCESSING/EF1_ALPHA/brain_state_folder')\n",
    "        df_1.to_csv(str(animal_id) +'_part_1.csv', index=True) \n",
    "        df_2.to_csv(str(animal_id) +'_part_2.csv', index=True)\n",
    "    else:\n",
    "        epochs_letter = raw_epochs_letter[epoch_letter_col]\n",
    "        drop_na = epochs_letter.dropna()\n",
    "        length_col = len(drop_na) \n",
    "        epoch_column_raw = raw_epochs[epoch]\n",
    "        all_epochs = epoch_column_raw[0:length_col].astype(int)\n",
    "        all_epochs_letter = epochs_letter[0:length_col]\n",
    "        discard_data = raw_discard[discard_col]\n",
    "        all_discard_epochs = discard_data[0:length_col] \n",
    "        data_dict = {'epoch_numbers': all_epochs, 'brain_state': all_epochs_letter,\n",
    "                       'epoch_discard_numbers': all_discard_epochs}\n",
    "        os.chdir('/home/melissa/PREPROCESSING/EF1_ALPHA/brain_state_folder')\n",
    "        data_df = pd.DataFrame(data = data_dict)\n",
    "        data_df.to_csv(str(animal_id) +'.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23787f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/PREPROCESSING/EF1_ALPHA/brain_state_folder')\n",
    "test_check = pd.read_csv('191125_A_part_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_indices = test_check.loc[test_check['brain_state'] == 'W'].index.tolist()\n",
    "rem_indices = test_check.loc[test_check['brain_state'] == 'R']\n",
    "nonrem_indices = test_check.loc[test_check['brain_state'] == 'N']\n",
    "discard_indices = test_check.loc[test_check['epoch_discard_numbers'] == 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaddcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_indices_list = wake_indices.index.tolist()\n",
    "rem_indices_list = rem_indices.index.tolist()\n",
    "nonrem_indices_list = nonrem_indices.index.tolist()\n",
    "discard_indices_list = discard_indices.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d200ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_match_elements(list_a, list_b):\n",
    "    non_match = []\n",
    "    for i in list_a:\n",
    "        if i not in list_b:\n",
    "            non_match.append(i)\n",
    "    return non_match\n",
    "\n",
    "new_list = non_match_elements(wake_indices_list, discard_indices_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3847cdd",
   "metadata": {},
   "source": [
    "## check that code works on individual animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff93b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/PROJECT_DIRECTORIES/ef1_alpha_analysis')\n",
    "%run preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb21502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths \n",
    "recording_path = '/home/melissa/PREPROCESSING/EF1_ALPHA'\n",
    "brain_state_path = '/home/melissa/PREPROCESSING/EF1_ALPHA/brain_state_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b2a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/PROJECT_DIRECTORIES/ef1_alpha_analysis')\n",
    "%run ef1_alpha_properties.py\n",
    "%run preprocess.py\n",
    "%run filter.py\n",
    "%run power.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a1802d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': ['191125', '191126'],\n",
       " 'A_1': ['191217'],\n",
       " 'B': ['191217', '210705'],\n",
       " 'B_1': ['210422', '210423'],\n",
       " 'C': ['210705', '191217'],\n",
       " 'D': ['210422', '210423', '210705']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordings_2_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb314196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [2, 3, 7, 9],\n",
       " 'A_1': [2, 3, 7, 8],\n",
       " 'B': [18, 19, 23, 25],\n",
       " 'B_1': [18, 20, 23, 25],\n",
       " 'C': [34, 35, 39, 41],\n",
       " 'D': [50, 51, 55, 57]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cb2384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 lists of letters - 1 for one recording and 1 for two recording\n",
    "recordings_letters_1 = ['A', 'A_1', 'B', 'C', 'D']\n",
    "recording_letters_2 = ['A', 'A_1', 'B', 'B_1', 'C', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "032bec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'create_epoch_bins', 'epoch_length', 'get_epoch_indices', 'load_brain_state_file', 'load_npy_recordings', 'remove_E_epochs', 'sample_rate']\n"
     ]
    }
   ],
   "source": [
    " print (dir(ExtractBrainStateEF1ALPHA)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89efec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/PREPROCESSING/EF1_ALPHA/two_recording/Part_2')\n",
    "part_2 = np.load('191217_part2_A_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ef22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_id = '191125'\n",
    "letter = 'A'\n",
    "os.chdir('/home/melissa/PREPROCESSING/EF1_ALPHA/brain_state_folder')\n",
    "state_file_names = os.listdir('/home/melissa/PREPROCESSING/EF1_ALPHA/brain_state_folder')\n",
    "for file in state_file_names:\n",
    "    if file.startswith(animal_id) and file.endswith(letter + '_part_1.csv'):\n",
    "        part_1_brain_state = pd.read_csv(file)\n",
    "    if file.startswith(animal_id) and file.endswith(letter + '_part_2.csv'):\n",
    "        part_2_brain_state = pd.read_csv(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for brainstate in brainstates:\n",
    "    for headstage_letters in recording_letters_2:\n",
    "        print(headstage_letters)\n",
    "        for anim_id in recordings_2_channels[headstage_letters]:\n",
    "            print(anim_id)\n",
    "            preprocessing_steps = ExtractBrainStateEF1ALPHA(anim_id, recording_path, brain_state_path, \n",
    "                                                            headstage_letters, recording_number=2)\n",
    "            part_1, part_2 = preprocessing_steps.load_npy_recordings()\n",
    "            part_1_br_state, part_2_br_state = preprocessing_steps.load_brain_state_file()\n",
    "            if part_1 and part_2 is not None:\n",
    "                epoch_indices_1 = preprocessing_steps.remove_E_epochs(part_1_br_state, brain_state_letter=brainstate)\n",
    "                epoch_indices_2 = preprocessing_steps.remove_E_epochs(part_2_br_state, brain_state_letter=brainstate)\n",
    "                epoch_bins_1 = preprocessing_steps.get_epoch_indices(part_1_br_state, epoch_indices_1)\n",
    "                epoch_bins_2 = preprocessing_steps.get_epoch_indices(part_2_br_state, epoch_indices_2)\n",
    "                for column, channel in zip(part_1_br_state.T, channels_dict[headstage_letters]):\n",
    "                    filter_steps = Filter(column, epoch_bins_1)\n",
    "                    filtered_data_1 = filter_steps.butter_bandpass()\n",
    "                    power_steps = PowerSpectrum(filtered_data_1)\n",
    "                    power_array_part_1, frequency_array_part_1 = power_steps.average_psd()\n",
    "                for column, channel in zip(part_2_br_state.T, channels_dict[headstage_letters]):\n",
    "                    filter_steps = Filter(column, epoch_bins_2)\n",
    "                    filtered_data_2 = filter_steps.butter_bandpass()\n",
    "                    power_steps = PowerSpectrum(filtered_data_2)\n",
    "                    power_array_part_2, frequency_array_part_2 = power_steps.average_psd()\n",
    "                average_power_array = average_power_df(power_array_part_1, power_array_part_2)\n",
    "                dict_data = {'Animal_ID': [anim_id]*len(average_power_array), 'Headstage':[headstage_letters]*len(average_power_array),\n",
    "                            'Channel': [channel]*len(average_power_array), 'Brainstate': [brainstate]*len(average_power_array),\n",
    "                            'Power': average_power_array, 'Frequency': frequency_array_part_1,}\n",
    "                two_recording.append(pd.DataFrame(data=dict_data))\n",
    "    merged_power_file = pd.conctenate(one_recording, axis = 0).drop_duplicates().reset_index(drop = True)\n",
    "    os.chdir('/home/melissa/RESULTS/EF1_ALPHA/2_REC')\n",
    "    merged_power_file.to_csv(str(brainstate) + '_2_rec.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088abd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_recording = []\n",
    "for letters_1 in recordings_letters_1:\n",
    "    for anim_id in recordings_1_channels[letters_1]:\n",
    "        testing_class = ExtractBrainStateEF1ALPHA(anim_id, recording_path, brain_state_path, letters_1, recording_number = 1)\n",
    "        npy_recording = testing_class.load_npy_recordings()\n",
    "        print(npy_recording)\n",
    "        br_state_files = testing_class.load_brain_state_file()\n",
    "        if br_state_files is not None:\n",
    "            br_state_indices = testing_class.remove_E_epochs(br_state_files, brain_state_letter = 'W')\n",
    "            epoch_indices = testing_class.get_epoch_indices(br_state_indices)\n",
    "            epoch_bins = testing_class.create_epoch_bins(br_state_files, epoch_indices)\n",
    "            if npy_recording is not None:\n",
    "                for column, channel in zip(npy_recording.T, channels_dict[letters_1]):\n",
    "                    filter_test = Filter(column, epoch_bins)\n",
    "                    filtered_data = filter_test.butter_bandpass()\n",
    "                    power_test = PowerSpectrum(filtered_data)\n",
    "                    power_array, frequency_array = power_test.average_psd()\n",
    "                    dict_data = {'Animal_ID': [anim_id]*len(power_array), 'Headstage': [letters_1]*len(power_array),\n",
    "                            'Channel': [channel]*len(power_array), 'Power': power_array, 'Frequency': frequency_array,\n",
    "                                'BrainState': ['W']*len(power_array)}\n",
    "                    one_recording.append(pd.DataFrame(data = dict_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3559c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_power_file = pd.concat(one_recording, axis=0).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62072548",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/RESULTS/EF1_ALPHA/2_REC')\n",
    "#merged_power_file.to_csv('one_recording_wake.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f41a1448023d8366d46bdc1967babc49ad1fb1468381993cc01a260a0f4f6641"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
